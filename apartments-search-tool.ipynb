{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3794981f",
   "metadata": {},
   "source": [
    "# Web Scraping Apartments Website\n",
    "\n",
    "View apartments in a city of your choice to see what is available by way of amenities, price, and number of rooms. It really is customizable to your own needs so feel free to play around with it if you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96325134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our necessary imports\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e428d1",
   "metadata": {},
   "source": [
    "## Instantiate all our variables\n",
    "**Note** `city-state` must be defined in a specific manner as noted in the code, while '1-bedrooms' in the link can be modified to fit your own needs. I just needed the 1-bedrooms though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a937d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique amenities is to make each one its own column\n",
    "unique_amenities = set()\n",
    "data = []\n",
    "# `city_state` must be formatted in the following way: 'atlanta-ga'\n",
    "city_state = ''\n",
    "\n",
    "# Assign for our driver\n",
    "service = Service(executable_path = 'C:/Users/Brady/anaconda3/chromedriver.exe')\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# Create the WebDriver using ChromeOptions\n",
    "driver = webdriver.Chrome(service = service, options = options)\n",
    "driver.get('https://www.apartments.com/{}/1-bedrooms'.format(city_state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the pages while there is another page\n",
    "while True:\n",
    "    \n",
    "    # Create the lxml of each page and find each post (postings)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    postings = soup.find_all('li', class_ = 'mortar-wrapper')\n",
    "\n",
    "    # Loop through each post on the current page\n",
    "    for post in postings: \n",
    "        \n",
    "        # Get the link of the website, the apartment complex name, \n",
    "        # address, price, and amenities of each listing\n",
    "        link = post.find('a', class_ = 'property-link').get('href')\n",
    "        apt_complex = post.find('span', class_ = 'js-placardTitle title').text\n",
    "        try:\n",
    "            address = post.find('div', class_ = 'property-address js-url').text\n",
    "        except:\n",
    "            address = 'N/A'\n",
    "        try:\n",
    "            price = post.find('p', class_ = 'property-pricing').text\n",
    "        except:\n",
    "            price = 'N/A'\n",
    "        try:\n",
    "            amenities = post.find('p', class_ = 'property-amenities').text.strip()\n",
    "            # Split the input string into separate lines\n",
    "            amenities_list = amenities.split('\\n')\n",
    "            # Remove empty lines\n",
    "            amenities_list = [amenity.strip() for amenity in amenities_list if amenity.strip()]\n",
    "            unique_amenities.update(amenities_list)\n",
    "        except:\n",
    "            amenities = 'N/A'\n",
    "        data.append({'Apartment Complex' : apt_complex, 'Website' : link, 'Address' : address,\n",
    "                    'Price' : price, 'Amenities' : amenities_list})\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, 'next ').click()\n",
    "        sleep(5)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d26eb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Turn our data list of dictionaries into a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Turn each amenity into its own column\n",
    "for amenity in unique_amenities:\n",
    "    df[amenity] = df['Amenities'].apply(lambda am: int(amenity in am))\n",
    "df = df.drop(columns=['Amenities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea365220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate columns for lower and upper prices\n",
    "df[['Lower Price', 'Upper Price']] = df['Price'].str.split('-', expand=True)\n",
    "df = df.drop(columns=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "unique_amenities\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13946dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our dataframe to a folder in order to access from Power BI\n",
    "df.to_csv('C:/Users/Brady/Web Scraping/plano-apartments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "complex_data = []\n",
    "for entry in data:\n",
    "    complex_data.append({\n",
    "        \"Name\": entry[\"Apartment Complex\"],\n",
    "        \"Website\": entry[\"Website\"],\n",
    "        \"Address\": entry[\"Address\"],\n",
    "        \"Price\": entry[\"Price\"],\n",
    "        \"Amenities\" : entry[\"Amenities\"]\n",
    "        })\n",
    "\n",
    "# Create a dictionary to map amenities to IDs\n",
    "amenity_id_map = {}\n",
    "next_amenity_id = 1\n",
    "\n",
    "# Process amenities and create ID mapping\n",
    "for comp in complex_data:\n",
    "    for amenity in comp[\"Amenities\"]:\n",
    "        if amenity not in amenity_id_map:\n",
    "            amenity_id_map[amenity] = next_amenity_id\n",
    "            next_amenity_id += 1\n",
    "\n",
    "# Process amenities and create associations\n",
    "complex_amenities_data = []\n",
    "for comp in complex_data:\n",
    "    complex_name = comp[\"Name\"]\n",
    "    for amenity in comp[\"Amenities\"]:\n",
    "        complex_amenities_data.append({\n",
    "            \"ComplexName\": complex_name,\n",
    "            \"AmenityID\": amenity_id_map[amenity],  # Use the ID from the mapping\n",
    "            \"AmenityName\": amenity\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the amenity_id_map dictionary\n",
    "complex_amenities = pd.DataFrame.from_dict(amenity_id_map, orient='index', columns=['AmenityID'])\n",
    "\n",
    "# Reset the index to make the amenity names a column\n",
    "complex_amenities.reset_index(inplace=True)\n",
    "complex_amenities.rename(columns={'index': 'AmenityName'}, inplace=True)\n",
    "\n",
    "# Save them to dataframes\n",
    "apt_complex = pd.DataFrame(complex_data)\n",
    "complex_amenities_map = pd.DataFrame(complex_amenities_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0029fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all your dataframes to a local csv file\n",
    "\n",
    "complex_amenities.to_csv('C:/Users/Brady/Web Scraping/complex_amenities.csv', index = False)\n",
    "apt_complex.to_csv('C:/Users/Brady/Web Scraping/apts.csv', index = False)\n",
    "complex_amenities_map.to_csv('C:/Users/Brady/Web Scraping/copmlex_amenities_map.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e25e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
